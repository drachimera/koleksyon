{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows how to do feature encoding for two simple datasets, one regression problem and one binary classification problem.  Feature encoding is where you change the way data is represented in the table so that algorithms can understand the pattern better.  Most algorithms only understand numbers (not strings, dates or categories) so the data needs to be converted into something the algorithms can understand.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import koleksyon.encode as ee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, here is an example of using the library to encode data for a classification problem.  We will use the adult dataset from UCI machine learning (https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data).  This data categorizes adults having an income greater than or equal to 50K or less than 50K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          workclass  fnlwgt    education  educational-num  \\\n",
       "0       39          State-gov   77516    Bachelors               13   \n",
       "1       50   Self-emp-not-inc   83311    Bachelors               13   \n",
       "2       38            Private  215646      HS-grad                9   \n",
       "3       53            Private  234721         11th                7   \n",
       "4       28            Private  338409    Bachelors               13   \n",
       "...    ...                ...     ...          ...              ...   \n",
       "32556   27            Private  257302   Assoc-acdm               12   \n",
       "32557   40            Private  154374      HS-grad                9   \n",
       "32558   58            Private  151910      HS-grad                9   \n",
       "32559   22            Private  201490      HS-grad                9   \n",
       "32560   52       Self-emp-inc  287927      HS-grad                9   \n",
       "\n",
       "            marital-status          occupation    relationship    race  \\\n",
       "0            Never-married        Adm-clerical   Not-in-family   White   \n",
       "1       Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "2                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "3       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "4       Married-civ-spouse      Prof-specialty            Wife   Black   \n",
       "...                    ...                 ...             ...     ...   \n",
       "32556   Married-civ-spouse        Tech-support            Wife   White   \n",
       "32557   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
       "32558              Widowed        Adm-clerical       Unmarried   White   \n",
       "32559        Never-married        Adm-clerical       Own-child   White   \n",
       "32560   Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "\n",
       "        gender  capital-gain  capital-loss  hours-per-week  native-country  \\\n",
       "0         Male          2174             0              40   United-States   \n",
       "1         Male             0             0              13   United-States   \n",
       "2         Male             0             0              40   United-States   \n",
       "3         Male             0             0              40   United-States   \n",
       "4       Female             0             0              40            Cuba   \n",
       "...        ...           ...           ...             ...             ...   \n",
       "32556   Female             0             0              38   United-States   \n",
       "32557     Male             0             0              40   United-States   \n",
       "32558   Female             0             0              40   United-States   \n",
       "32559     Male             0             0              20   United-States   \n",
       "32560   Female         15024             0              40   United-States   \n",
       "\n",
       "       income  \n",
       "0       <=50K  \n",
       "1       <=50K  \n",
       "2       <=50K  \n",
       "3       <=50K  \n",
       "4       <=50K  \n",
       "...       ...  \n",
       "32556   <=50K  \n",
       "32557    >50K  \n",
       "32558   <=50K  \n",
       "32559   <=50K  \n",
       "32560    >50K  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'educational-num','marital-status',\n",
    "                        'occupation', 'relationship', 'race', 'gender','capital-gain', 'capital-loss',\n",
    "                        'hours-per-week', 'native-country','income']\n",
    "df = pd.read_csv(\"../../data/adult.data\", names=column_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'target' or variable we are trying to predict is 'income'.  There are many different encoders we could use, so we will use koleksyon to compare the various encoders and see which one works best for this data.  The way this works is it will construct a random forest (a simple algorithm that we can improve on later) and place that random forest in an encoding pipeline.  It will then benchmark a pipeline for each type of encoder in the category_encoders library to help us determine the best way to handle our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = \"income\"\n",
    "ep = ee.EncodePipeline(df, target_name, \"classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************\n",
      "Benchmarking Encoders...\n",
      "*******************************************************************\n",
      "Preparing Data...\n",
      "Building Train/Test dataset\n",
      "*******************************************************************\n",
      "Building Simple Algorithm...\n",
      "Evaluating Encoders...\n",
      "*******************************************************************\n",
      "<class 'category_encoders.backward_difference.BackwardDifferenceEncoder'>\n",
      "Training....\n",
      "Predicting....\n",
      "{'accuracy_score': 0.8570551205281745, 'true_positives': 4646, 'false_positives': 363, 'false_negatives': 568, 'true_negatives': 936, 'f1_score': 0.7883933554653106, 'precision': 0.9275304451986425, 'recall': 0.8910625239739164, 'roc_auc': 0.7749354353652786}\n",
      "*******************************************************************\n",
      "<class 'category_encoders.basen.BaseNEncoder'>\n",
      "Training....\n",
      "Predicting....\n",
      "{'accuracy_score': 0.8587440503608168, 'true_positives': 4658, 'false_positives': 351, 'false_negatives': 569, 'true_negatives': 935, 'f1_score': 0.7901860185640392, 'precision': 0.9299261329606708, 'recall': 0.8911421465467764, 'roc_auc': 0.7758008324377823}\n",
      "*******************************************************************\n",
      "<class 'category_encoders.binary.BinaryEncoder'>\n",
      "Training....\n",
      "Predicting....\n",
      "{'accuracy_score': 0.8576692768309535, 'true_positives': 4651, 'false_positives': 358, 'false_negatives': 569, 'true_negatives': 935, 'f1_score': 0.7889743885403244, 'precision': 0.9285286484328209, 'recall': 0.8909961685823755, 'roc_auc': 0.7751020901738572}\n",
      "*******************************************************************\n",
      "<class 'category_encoders.cat_boost.CatBoostEncoder'>\n",
      "Training....\n",
      "Predicting....\n",
      "{'accuracy_score': 0.865806847842776, 'true_positives': 4677, 'false_positives': 332, 'false_negatives': 542, 'true_negatives': 962, 'f1_score': 0.8010911615453576, 'precision': 0.933719305250549, 'recall': 0.8961486874880246, 'roc_auc': 0.7866734824125086}\n",
      "*******************************************************************\n",
      "<class 'category_encoders.hashing.HashingEncoder'>\n",
      "Training....\n",
      "Predicting....\n",
      "{'accuracy_score': 0.8429295255642562, 'true_positives': 4635, 'false_positives': 374, 'false_negatives': 649, 'true_negatives': 855, 'f1_score': 0.7631490628642253, 'precision': 0.9253343980834497, 'recall': 0.8771763815291446, 'roc_auc': 0.7469092203183205}\n",
      "*******************************************************************\n",
      "<class 'category_encoders.helmert.HelmertEncoder'>\n",
      "Training....\n",
      "Predicting....\n",
      "{'accuracy_score': 0.8550591125441425, 'true_positives': 4631, 'false_positives': 378, 'false_negatives': 566, 'true_negatives': 938, 'f1_score': 0.7863768079686125, 'precision': 0.924535835496107, 'recall': 0.8910910140465653, 'roc_auc': 0.7741030241310322}\n",
      "*******************************************************************\n",
      "<class 'category_encoders.james_stein.JamesSteinEncoder'>\n",
      "Training....\n",
      "Predicting....\n",
      "{'accuracy_score': 0.8599723629663749, 'true_positives': 4646, 'false_positives': 363, 'false_negatives': 549, 'true_negatives': 955, 'f1_score': 0.793724115916244, 'precision': 0.9275304451986425, 'recall': 0.8943214629451396, 'roc_auc': 0.7812519247269807}\n",
      "*******************************************************************\n",
      "<class 'category_encoders.one_hot.OneHotEncoder'>\n",
      "Training....\n",
      "Predicting....\n",
      "{'accuracy_score': 0.8552126516198373, 'true_positives': 4628, 'false_positives': 381, 'false_negatives': 562, 'true_negatives': 942, 'f1_score': 0.7869854001583556, 'precision': 0.9239369135555999, 'recall': 0.8917148362235068, 'roc_auc': 0.7751333503948212}\n",
      "*******************************************************************\n",
      "<class 'category_encoders.leave_one_out.LeaveOneOutEncoder'>\n",
      "Training....\n",
      "Predicting....\n",
      "{'accuracy_score': 0.7690772301550745, 'true_positives': 5009, 'false_positives': 0, 'false_negatives': 1504, 'true_negatives': 0, 'f1_score': 0.434733553202569, 'precision': 1.0, 'recall': 0.7690772301550745, 'roc_auc': 0.5}\n",
      "*******************************************************************\n",
      "<class 'category_encoders.m_estimate.MEstimateEncoder'>\n",
      "Training....\n",
      "Predicting....\n",
      "{'accuracy_score': 0.8598188238906802, 'true_positives': 4646, 'false_positives': 363, 'false_negatives': 550, 'true_negatives': 954, 'f1_score': 0.7934449770488399, 'precision': 0.9275304451986425, 'recall': 0.8941493456505004, 'roc_auc': 0.78091947791847}\n",
      "*******************************************************************\n",
      "<class 'category_encoders.ordinal.OrdinalEncoder'>\n",
      "Training....\n",
      "Predicting....\n",
      "{'accuracy_score': 0.8584369722094273, 'true_positives': 4659, 'false_positives': 350, 'false_negatives': 572, 'true_negatives': 932, 'f1_score': 0.7895102605662241, 'precision': 0.9301257736075065, 'recall': 0.8906518830051615, 'roc_auc': 0.7749033123356682}\n",
      "*******************************************************************\n",
      "<class 'category_encoders.polynomial.PolynomialEncoder'>\n",
      "Training....\n",
      "Predicting....\n",
      "{'accuracy_score': 0.8536772608628896, 'true_positives': 4614, 'false_positives': 395, 'false_negatives': 558, 'true_negatives': 946, 'f1_score': 0.785710312931718, 'precision': 0.9211419444999002, 'recall': 0.8921113689095128, 'roc_auc': 0.7750656531010138}\n",
      "*******************************************************************\n",
      "<class 'category_encoders.sum_coding.SumEncoder'>\n",
      "Training....\n",
      "Predicting....\n",
      "{'accuracy_score': 0.8561338860740059, 'true_positives': 4632, 'false_positives': 377, 'false_negatives': 560, 'true_negatives': 944, 'f1_score': 0.788232422120684, 'precision': 0.9247354761429427, 'recall': 0.8921417565485362, 'roc_auc': 0.7761975253055139}\n",
      "*******************************************************************\n",
      "<class 'category_encoders.target_encoder.TargetEncoder'>\n",
      "Training....\n",
      "Predicting....\n",
      "{'accuracy_score': 0.8593582066635959, 'true_positives': 4644, 'false_positives': 365, 'false_negatives': 551, 'true_negatives': 953, 'f1_score': 0.792819397126403, 'precision': 0.9271311639049711, 'recall': 0.8939364773820981, 'roc_auc': 0.7803873904631238}\n",
      "*******************************************************************\n",
      "<class 'category_encoders.woe.WOEEncoder'>\n",
      "Training....\n",
      "Predicting....\n",
      "{'accuracy_score': 0.8602794411177644, 'true_positives': 4643, 'false_positives': 366, 'false_negatives': 544, 'true_negatives': 960, 'f1_score': 0.7945972715691181, 'precision': 0.9269315232581353, 'recall': 0.8951224214382109, 'roc_auc': 0.7826146977992804}\n"
     ]
    }
   ],
   "source": [
    "results = ep.evaluate_encoders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
